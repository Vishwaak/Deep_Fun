{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MAML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOuid3HtrZhLyfLENM2rCbi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vishwaak/Deep_Fun/blob/master/MAML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eHuX5QPkUf4",
        "colab_type": "code",
        "outputId": "f2d0fde1-2261-4a65-c413-d99ae7e0d770",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "!pip install learn2learn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting learn2learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/a3/47acb68bd34354502b39827a6a4e5091e4b1601c70228bf7d77ca1c1bb88/learn2learn-0.1.0.1.tar.gz (533kB)\n",
            "\r\u001b[K     |▋                               | 10kB 26.8MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |█▉                              | 30kB 4.5MB/s eta 0:00:01\r\u001b[K     |██▌                             | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 3.7MB/s eta 0:00:01\r\u001b[K     |███▊                            | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |████▎                           | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 81kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 92kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 133kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 143kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 153kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 163kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 174kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 184kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 194kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 204kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 215kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 225kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 235kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 245kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 256kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 266kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 276kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 286kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 296kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 307kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 317kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 327kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 337kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 348kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 358kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 368kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 378kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 389kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 399kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 409kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 419kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 430kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 440kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 450kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 460kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 471kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 481kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 491kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 501kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 512kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 522kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 532kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 542kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from learn2learn) (1.18.2)\n",
            "Requirement already satisfied: gym>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from learn2learn) (0.17.1)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from learn2learn) (1.4.0)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from learn2learn) (0.5.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from learn2learn) (0.25.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from learn2learn) (2.21.0)\n",
            "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.14.0->learn2learn) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym>=0.14.0->learn2learn) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym>=0.14.0->learn2learn) (1.12.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.14.0->learn2learn) (1.5.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->learn2learn) (7.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->learn2learn) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->learn2learn) (2018.9)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->learn2learn) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->learn2learn) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->learn2learn) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->learn2learn) (1.24.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.14.0->learn2learn) (0.16.0)\n",
            "Building wheels for collected packages: learn2learn\n",
            "  Building wheel for learn2learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for learn2learn: filename=learn2learn-0.1.0.1-cp36-cp36m-linux_x86_64.whl size=850195 sha256=cf53ef5b1098265bd7115e29d907f9f014d5b57553c1f879d6302811e0cc6155\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/5f/e9/9a11f45835f6f9163aa311c673185bd50d1dea5fed29ac882a\n",
            "Successfully built learn2learn\n",
            "Installing collected packages: learn2learn\n",
            "Successfully installed learn2learn-0.1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvTtNwomta0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6TpaN1KnCt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import numpy as  np\n",
        "import torch \n",
        "from PIL.Image import LANCZOS\n",
        "from torch import nn,optim\n",
        "from torchvision import transforms\n",
        "import learn2learn as l2l\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9l85JzEXuc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def accuracy(predictions, targets):\n",
        "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
        "    return (predictions == targets).sum().float() / targets.size(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpXGZI_GaAVa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def fast_adapt(batch, learner, loss, adaptation_steps, shots, ways, device):\n",
        "    data, labels = batch\n",
        "    data, labels = data.to(device), labels.to(device)\n",
        "\n",
        "    # Separate data into adaptation/evalutation sets\n",
        "    adaptation_indices = np.zeros(data.size(0), dtype=bool)\n",
        "    adaptation_indices[np.arange(shots*ways) * 2] = True\n",
        "    evaluation_indices = torch.from_numpy(~adaptation_indices)\n",
        "    adaptation_indices = torch.from_numpy(adaptation_indices)\n",
        "    adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
        "    evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
        "\n",
        "    # Adapt the model\n",
        "    for step in range(adaptation_steps):\n",
        "        train_error = loss(learner(adaptation_data), adaptation_labels)\n",
        "        train_error /= len(adaptation_data)\n",
        "        learner.adapt(train_error)\n",
        "\n",
        "    # Evaluate the adapted model\n",
        "    predictions = learner(evaluation_data)\n",
        "    valid_error = loss(predictions, evaluation_labels)\n",
        "    valid_error /= len(evaluation_data)\n",
        "    valid_accuracy = accuracy(predictions, evaluation_labels)\n",
        "    return valid_error, valid_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04kBGdATFzdr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main(\n",
        "        ways=5,\n",
        "        shots=1,\n",
        "        meta_lr=0.003,\n",
        "        fast_lr=0.5,\n",
        "        meta_batch_size=32,\n",
        "        adaptation_steps=1,\n",
        "        num_iterations=60000,\n",
        "        cuda=True,\n",
        "        seed=42,\n",
        "):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    device = torch.device('cpu')\n",
        "    if cuda:\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        device = torch.device('cuda')\n",
        "    #Dataset download\n",
        "    omniglot = l2l.vision.datasets.FullOmniglot(root='~/data',\n",
        "                                                transform=transforms.Compose([\n",
        "                                                    transforms.Resize(28, interpolation=LANCZOS),\n",
        "                                                    transforms.ToTensor(),\n",
        "                                                    lambda x: 1.0 - x,\n",
        "                                                ]),\n",
        "                                                download=True)\n",
        "    dataset = l2l.data.MetaDataset(omniglot)\n",
        "    classes = list(range(1623))\n",
        "    print(dataset)\n",
        "\n",
        "    random.shuffle(classes)\n",
        "    #Data Augmentation\n",
        "    train_transforms = [\n",
        "        l2l.data.transforms.FusedNWaysKShots(dataset,\n",
        "                                             n=ways,\n",
        "                                             k=2*shots,\n",
        "                                             filter_labels=classes[:1100]),\n",
        "        l2l.data.transforms.LoadData(dataset),\n",
        "        l2l.data.transforms.RemapLabels(dataset),\n",
        "        l2l.data.transforms.ConsecutiveLabels(dataset),\n",
        "        l2l.vision.transforms.RandomClassRotation(dataset, [0.0, 90.0, 180.0, 270.0])\n",
        "    ]\n",
        "    train_tasks = l2l.data.TaskDataset(dataset,\n",
        "                                       task_transforms=train_transforms,\n",
        "                                       num_tasks=20000)\n",
        "\n",
        "    valid_transforms = [\n",
        "        l2l.data.transforms.FusedNWaysKShots(dataset,\n",
        "                                             n=ways,\n",
        "                                             k=2*shots,\n",
        "                                             filter_labels=classes[1100:1200]),\n",
        "        l2l.data.transforms.LoadData(dataset),\n",
        "        l2l.data.transforms.RemapLabels(dataset),\n",
        "        l2l.data.transforms.ConsecutiveLabels(dataset),\n",
        "        l2l.vision.transforms.RandomClassRotation(dataset, [0.0, 90.0, 180.0, 270.0])\n",
        "    ]\n",
        "    valid_tasks = l2l.data.TaskDataset(dataset,\n",
        "                                       task_transforms=valid_transforms,\n",
        "                                       num_tasks=1024)\n",
        "\n",
        "    test_transforms = [\n",
        "        l2l.data.transforms.FusedNWaysKShots(dataset,\n",
        "                                             n=ways,\n",
        "                                             k=2*shots,\n",
        "                                             filter_labels=classes[1200:]),\n",
        "        l2l.data.transforms.LoadData(dataset),\n",
        "        l2l.data.transforms.RemapLabels(dataset),\n",
        "        l2l.data.transforms.ConsecutiveLabels(dataset),\n",
        "        l2l.vision.transforms.RandomClassRotation(dataset, [0.0, 90.0, 180.0, 270.0])\n",
        "    ]\n",
        "    test_tasks = l2l.data.TaskDataset(dataset,\n",
        "                                      task_transforms=test_transforms,\n",
        "                                      num_tasks=1024)\n",
        "\n",
        "    # Create model\n",
        "    model = l2l.vision.models.OmniglotFC(28 ** 2, ways)\n",
        "    model.to(device)\n",
        "    maml = l2l.algorithms.MAML(model, lr=fast_lr, first_order=False)\n",
        "    opt = optim.Adam(maml.parameters(), meta_lr)\n",
        "    loss = nn.CrossEntropyLoss(reduction='mean')\n",
        "\n",
        "    for iteration in range(num_iterations):\n",
        "        opt.zero_grad()\n",
        "        meta_train_error = 0.0\n",
        "        meta_train_accuracy = 0.0\n",
        "        meta_valid_error = 0.0\n",
        "        meta_valid_accuracy = 0.0\n",
        "        for task in range(meta_batch_size):\n",
        "            # Compute meta-training loss\n",
        "            learner = maml.clone()\n",
        "            batch = train_tasks.sample()\n",
        "            evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "                                                               learner,\n",
        "                                                               loss,\n",
        "                                                               adaptation_steps,\n",
        "                                                               shots,\n",
        "                                                               ways,\n",
        "                                                               device)\n",
        "            evaluation_error.backward()\n",
        "            meta_train_error += evaluation_error.item()\n",
        "            meta_train_accuracy += evaluation_accuracy.item()\n",
        "\n",
        "            # Compute meta-validation loss\n",
        "            learner = maml.clone()\n",
        "            batch = valid_tasks.sample()\n",
        "            evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "                                                               learner,\n",
        "                                                               loss,\n",
        "                                                               adaptation_steps,\n",
        "                                                               shots,\n",
        "                                                               ways,\n",
        "                                                               device)\n",
        "            meta_valid_error += evaluation_error.item()\n",
        "            meta_valid_accuracy += evaluation_accuracy.item()\n",
        "        \n",
        "        # Print some metrics\n",
        "        print('\\n')\n",
        "        print('Iteration', iteration)\n",
        "        print('Meta Train Error', meta_train_error / meta_batch_size)\n",
        "        print('Meta Train Accuracy', meta_train_accuracy / meta_batch_size)\n",
        "        print('Meta Valid Error', meta_valid_error / meta_batch_size)\n",
        "        print('Meta Valid Accuracy', meta_valid_accuracy / meta_batch_size)\n",
        "\n",
        "        # Average the accumulated gradients and optimize\n",
        "        for p in maml.parameters():\n",
        "            p.grad.data.mul_(1.0 / meta_batch_size)\n",
        "        opt.step()\n",
        "\n",
        "    meta_test_error = 0.0\n",
        "    meta_test_accuracy = 0.0\n",
        "    for task in range(meta_batch_size):\n",
        "        # Compute meta-testing loss\n",
        "        learner = maml.clone()\n",
        "        batch = test_tasks.sample()\n",
        "        evaluation_error, evaluation_accuracy = fast_adapt(batch,\n",
        "                                                           learner,\n",
        "                                                           loss,\n",
        "                                                           adaptation_steps,\n",
        "                                                           shots,\n",
        "                                                           ways,\n",
        "                                                           device)\n",
        "        meta_test_error += evaluation_error.item()\n",
        "        meta_test_accuracy += evaluation_accuracy.item()\n",
        "    print('Meta Test Error', meta_test_error / meta_batch_size)\n",
        "    print('Meta Test Accuracy', meta_test_accuracy / meta_batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njZuBNi3d8AG",
        "colab_type": "code",
        "outputId": "7832bc86-9b52-4a78-e0c0-35cca044fb75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "<learn2learn.data.meta_dataset.MetaDataset object at 0x7f71e25ca550>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-c82a4ea2317d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(ways, shots, meta_lr, fast_lr, meta_batch_size, adaptation_steps, num_iterations, cuda, seed)\u001b[0m\n\u001b[1;32m     97\u001b[0m                                                                \u001b[0mways\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                                                                device)\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mevaluation_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0mmeta_train_error\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mevaluation_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mmeta_train_accuracy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mevaluation_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}